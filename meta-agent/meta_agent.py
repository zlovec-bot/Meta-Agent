"""
Meta-Agent - èƒ½å¤Ÿåˆ›å»ºå…¶ä»– Agent çš„ Agent (ä½¿ç”¨ GLM-4)
"""
import json
from zhipuai import ZhipuAI
from meta_config import GLM_API_KEY, META_MODEL
from meta_tools import get_meta_tool_definitions, execute_meta_tool


class MetaAgent:
    def __init__(self):
        self.client = ZhipuAI(api_key=GLM_API_KEY)
        self.model = META_MODEL
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Agent å¼€å‘ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·éœ€æ±‚åˆ›å»ºæ–°çš„ Agentã€‚

å·¥ä½œæµç¨‹ï¼š
1. é¦–å…ˆä½¿ç”¨ list_template_files æŸ¥çœ‹å¯ç”¨çš„èŒƒä¾‹æ–‡ä»¶
2. ä½¿ç”¨ read_template_file è¯»å–ç›¸å…³èŒƒä¾‹æ–‡ä»¶ï¼Œç†è§£å…¶ç»“æ„
3. ä½¿ç”¨ create_agent_project åˆ›å»ºæ–°çš„ Agent é¡¹ç›®ï¼ˆè¿™ä¼šè‡ªåŠ¨å¤åˆ¶èŒƒä¾‹ä»£ç ï¼‰
4. æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œä½¿ç”¨ modify_agent_file ä¿®æ”¹å¿…è¦çš„æ–‡ä»¶ï¼š
   - tools.py: æ·»åŠ æˆ–ä¿®æ”¹å·¥å…·å®šä¹‰
   - agent.py: è°ƒæ•´ Agent è¡Œä¸ºå’Œç³»ç»Ÿæç¤ºè¯
   - config.py: å¦‚éœ€è¦å¯ä»¥è°ƒæ•´é…ç½®
   - requirements.txt: å¦‚éœ€è¦å¯ä»¥æ·»åŠ æ–°çš„ä¾èµ–

é‡è¦åŸåˆ™ï¼š
- ä¿æŒä»£ç ä½¿ç”¨ GLM-4 API æ ¼å¼
- ä½¿ç”¨æ™ºè°± AI çš„ Tool Calling åè®®
- ä¿æŒè‰¯å¥½çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- ç¡®ä¿ç”Ÿæˆçš„ä»£ç å¯ä»¥ç›´æ¥è¿è¡Œ
- æ‰€æœ‰ä»£ç ä½¿ç”¨ä¸­æ–‡æ³¨é‡Š
"""
        self.conversation_history = []
        self.tools = get_meta_tool_definitions()
        
    def create_agent(self, user_requirement):
        """æ ¹æ®ç”¨æˆ·éœ€æ±‚åˆ›å»º Agent"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹åˆ›å»º Agent")
        print(f"éœ€æ±‚: {user_requirement}")
        print(f"{'='*60}\n")
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.conversation_history.append({
            "role": "user",
            "content": f"è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚åˆ›å»ºä¸€ä¸ªæ–°çš„ Agentï¼š\n\n{user_requirement}"
        })
        
        iteration = 0
        max_iterations = 15
        
        while iteration < max_iterations:
            iteration += 1
            print(f"\n--- è¿­ä»£ {iteration} ---")
            
            # è°ƒç”¨ LLM
            response = self._call_llm()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
            if response.choices[0].finish_reason == "tool_calls":
                tool_calls = response.choices[0].message.tool_calls
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                assistant_message = {
                    "role": "assistant",
                    "content": response.choices[0].message.content or ""
                }
                
                # æ·»åŠ å·¥å…·è°ƒç”¨ä¿¡æ¯
                if tool_calls:
                    assistant_message["tool_calls"] = [
                        {
                            "id": tc.id,
                            "type": tc.type,
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        }
                        for tc in tool_calls
                    ]
                
                self.conversation_history.append(assistant_message)
                
                # æ‰§è¡Œå·¥å…·è°ƒç”¨
                for tool_call in tool_calls:
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)
                    
                    print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                    print(f"   å‚æ•°: {json.dumps(tool_args, ensure_ascii=False, indent=2)}")
                    
                    # æ‰§è¡Œå·¥å…·
                    tool_result = execute_meta_tool(tool_name, tool_args)
                    
                    # æ‰“å°ç»“æœï¼ˆç®€åŒ–ç‰ˆï¼‰
                    if tool_result.get("success"):
                        print(f"   âœ… æˆåŠŸ")
                    else:
                        print(f"   âŒ å¤±è´¥: {tool_result.get('error')}")
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°å†å²
                    self.conversation_history.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": json.dumps(tool_result, ensure_ascii=False)
                    })
                    
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆå“åº”
                final_response = response.choices[0].message.content
                self.conversation_history.append({
                    "role": "assistant",
                    "content": final_response
                })
                
                print(f"\n{'='*60}")
                print(f"Agent åˆ›å»ºå®Œæˆï¼")
                print(f"{'='*60}")
                print(f"\n{final_response}")
                
                return final_response
                
        return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ŒAgent å¯èƒ½æœªå®Œå…¨åˆ›å»º"
    
    def _call_llm(self):
        """è°ƒç”¨ GLM-4 API"""
        messages = [{"role": "system", "content": self.system_prompt}] + self.conversation_history
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            tools=self.tools,
            temperature=0.7
        )
        
        return response


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤º Meta-Agent ä½¿ç”¨"""
    meta_agent = MetaAgent()
    
    # ç¤ºä¾‹éœ€æ±‚
    requirement = """
åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿæœç´¢ç½‘ç»œå¹¶æ€»ç»“ä¿¡æ¯çš„ Agentã€‚

åŠŸèƒ½è¦æ±‚ï¼š
1. èƒ½å¤Ÿæ¥æ”¶ç”¨æˆ·çš„æœç´¢æŸ¥è¯¢
2. ä½¿ç”¨ web_search å·¥å…·æœç´¢ç›¸å…³ä¿¡æ¯
3. åˆ†ææœç´¢ç»“æœå¹¶ç”Ÿæˆç®€æ´çš„æ‘˜è¦
4. æ”¯æŒå¤šè½®å¯¹è¯ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·åé¦ˆè¿›ä¸€æ­¥æœç´¢

Agent åç§°ï¼šweb-research-agent
"""
    
    # åˆ›å»º Agent
    result = meta_agent.create_agent(requirement)
    
    print("\n" + "="*60)
    print("å®éªŒå®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    main()
